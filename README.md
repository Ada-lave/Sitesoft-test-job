# Как пользоваться?
Данный парсер позволяет собирать данные с сайта habr.ru и сохраняет их в базу данных sqlite3

## Как откуда беруться источники для парсинга
Источники указывается в таблице habs созданной базы данных
```
habs:
    id
    name - Имя хаба
    link - Ссылка до хаба, пример: https://habr.com/ru/hubs/programming/articles/
    interval - Интревал обхода в минутах
```

## Где лежат данные по публикациям
Данные находятся в таблице articles
```
articles:
    id
    heading - Заголовок публикации
    link - Ссылка до публикации
    author_name - Имя автора
    author_link - Ссылка до автора
    published_at - время публикации
    hab_id
```

# Как работает?
Данный парсер выполняет обход и парсинг данных асинхронно для каждого перечисленного хаба, выполняя асинхронные запросы за публикациями.


# Структура проекта
```
src
    db - класс для взаимодействия с БД
    models - Модели которые используются для удобства
        article.py - Модель публикации
        hab.py - Модель хаба
        
    parser - Класс парсера
    main.py - точка входа приложения
    db.sqlite3*
    dockerfile - Докер файл для запуска проекта в контейнере
```

- *База данные создается после запуска

_Ada_lave_